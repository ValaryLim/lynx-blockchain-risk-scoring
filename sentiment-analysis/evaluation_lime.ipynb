{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "a5152633bfa090882c4a32e13f4687160ad783c12ad45cc01f4b8ab7e34ddbcf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Evaluation Using Eli5 and Lime"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&amp;B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# word2vec pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from word2vec import get_embed_features_list\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# eli5\n",
    "import eli5\n",
    "from eli5.lime import TextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom transformer to embed words\n",
    "class FeatureEmbedder(BaseEstimator, TransformerMixin): \n",
    "    def __init__( self ):\n",
    "        return\n",
    "    \n",
    "    # Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    # Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return get_embed_features_list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filter functions\n",
    "def filter_entity(feature, entity_list):\n",
    "    '''\n",
    "    retrieve rows that have entity names\n",
    "    '''\n",
    "    # set everything to lowercase and split feature words\n",
    "    entity_list = set(x.lower() for x in entity_list)\n",
    "    feature_words = feature.lower().split()\n",
    "\n",
    "    for word in feature_words:\n",
    "        if word in entity_list:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def retrieve_entity(feature, entity_list):\n",
    "    '''\n",
    "    outputs entity that feature belongs to\n",
    "    '''\n",
    "    # set everything to lowercase and split feature words\n",
    "    entity_list = set(x.lower() for x in entity_list)\n",
    "    feature_words = feature.lower().split()\n",
    "\n",
    "    for word in feature_words:\n",
    "        if word in entity_list:\n",
    "            return word\n",
    "    return None # no word available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data\n",
    "all_train = pd.read_csv('data/all_train.csv', header = 0)[[\"date_time\", \"text\", \"label\"]]\n",
    "all_test = pd.read_csv('data/all_test.csv', header = 0)[[\"date_time\", \"text\", \"label\"]]\n",
    "all_sample = pd.concat([all_train, all_test], axis=0)\n",
    "\n",
    "# load entity list\n",
    "entity_list = set(pd.read_csv(\"data/entity_list.csv\", header=0)[\"entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             date_time                                               text  \\\n",
       "0  2018-01-01 06:14:00  will neo be considered a security?. gas paymen...   \n",
       "1  2018-01-01 19:53:00  better business bureau bittrex exchange grade ...   \n",
       "2  2018-01-01 20:03:00  better business bureau bittrex exchange grade ...   \n",
       "3  2018-01-01 20:13:00  better business bureau bittrex exchange grade ...   \n",
       "4  2018-01-01 22:39:00  account hacked ?. i have accounts on bitstamp ...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-01 06:14:00</td>\n      <td>will neo be considered a security?. gas paymen...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-01 19:53:00</td>\n      <td>better business bureau bittrex exchange grade ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-01 20:03:00</td>\n      <td>better business bureau bittrex exchange grade ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-01 20:13:00</td>\n      <td>better business bureau bittrex exchange grade ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-01 22:39:00</td>\n      <td>account hacked ?. i have accounts on bitstamp ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "all_sample.head()"
   ]
  },
  {
   "source": [
    "## Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('featureembedder', FeatureEmbedder()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# create pipeline\n",
    "vec = FeatureEmbedder()\n",
    "lr = LogisticRegression()\n",
    "pipe_lr = make_pipeline(vec, lr)\n",
    "pipe_lr.fit(all_train.text, all_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve all features and weights from all possible texts\n",
    "for i in range(len(all_sample)):\n",
    "    current_text = all_sample[\"text\"].iloc[i]\n",
    "    \n",
    "    # create text explainer\n",
    "    te_lr = TextExplainer(random_state=42)\n",
    "    te_lr.fit(current_text, pipe_lr.predict_proba)\n",
    "\n",
    "    # create dataframe from weights\n",
    "    current_df = eli5.formatters.as_dataframe.format_as_dataframes(te_lr.explain_weights(top=None))[\"targets\"]\n",
    "\n",
    "    if i == 0:\n",
    "        lr_df = current_df\n",
    "    else:\n",
    "        lr_df = pd.concat([current_df, lr_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           feature  target    weight\n",
       "0                0       1 -0.043764\n",
       "1       0 00033317       1  0.054758\n",
       "2         0 001012       1  0.079283\n",
       "3        0 0018978       1  0.085246\n",
       "4        0 0019049       1  0.030631\n",
       "...            ...     ...       ...\n",
       "105620         ð ³       1  0.100706\n",
       "105621        ð ³ð       1  0.023520\n",
       "105622         ð ¹       1  0.070897\n",
       "105623         ð â       1  0.089605\n",
       "105624         ð ð       1  0.098035\n",
       "\n",
       "[105625 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>target</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>-0.043764</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0 00033317</td>\n      <td>1</td>\n      <td>0.054758</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0 001012</td>\n      <td>1</td>\n      <td>0.079283</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0 0018978</td>\n      <td>1</td>\n      <td>0.085246</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0 0019049</td>\n      <td>1</td>\n      <td>0.030631</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>105620</th>\n      <td>ð ³</td>\n      <td>1</td>\n      <td>0.100706</td>\n    </tr>\n    <tr>\n      <th>105621</th>\n      <td>ð ³ð</td>\n      <td>1</td>\n      <td>0.023520</td>\n    </tr>\n    <tr>\n      <th>105622</th>\n      <td>ð ¹</td>\n      <td>1</td>\n      <td>0.070897</td>\n    </tr>\n    <tr>\n      <th>105623</th>\n      <td>ð â</td>\n      <td>1</td>\n      <td>0.089605</td>\n    </tr>\n    <tr>\n      <th>105624</th>\n      <td>ð ð</td>\n      <td>1</td>\n      <td>0.098035</td>\n    </tr>\n  </tbody>\n</table>\n<p>105625 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# retrieve mean of each weight\n",
    "lr_df_averaged = lr_df.groupby(\"feature\").mean()\n",
    "lr_df_averaged = lr_df_averaged.reset_index()\n",
    "\n",
    "lr_df_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   feature_entity  target    weight\n",
       "0         airswap       1  0.046664\n",
       "1         antpool       1  0.055153\n",
       "2          bancor       1  0.053066\n",
       "3         binance       1  0.052430\n",
       "4          bitbox       1  0.079381\n",
       "5     bitclubpool       1 -0.004001\n",
       "6        bitfinex       1  0.006632\n",
       "7         bithumb       1 -0.028046\n",
       "8         bitmart       1  0.046159\n",
       "9        bitstamp       1  0.034608\n",
       "10        bittrex       1  0.011911\n",
       "11      cobinhood       1 -0.038470\n",
       "12           cobo       1  0.031416\n",
       "13       coinbase       1  0.069406\n",
       "14      coincheck       1  0.018296\n",
       "15         coinex       1  0.010552\n",
       "16       coinmine       1  0.038310\n",
       "17        coinone       1  0.018185\n",
       "18       coinrail       1 -0.018699\n",
       "19  cryptokitties       1  0.059341\n",
       "20      cryptopia       1  0.013216\n",
       "21           dapp       1  0.097309\n",
       "22   decentraland       1 -0.005803\n",
       "23      deversifi       1 -0.024478\n",
       "24            dex       1  0.087949\n",
       "25       dragonex       1 -0.034751\n",
       "26     etherdelta       1 -0.017438\n",
       "27       ethfinex       1  0.036497\n",
       "28           exmo       1  0.056855\n",
       "29          fcoin       1 -0.015262\n",
       "30         gemini       1  0.069898\n",
       "31         hitbtc       1  0.027404\n",
       "32          huobi       1  0.021553\n",
       "33          hydro       1  0.028304\n",
       "34           idex       1  0.043237\n",
       "35         kraken       1  0.076676\n",
       "36         kucoin       1  0.078712\n",
       "37        latoken       1  0.019631\n",
       "38         liquid       1  0.120405\n",
       "39           luno       1 -0.025950\n",
       "40          maker       1  0.072371\n",
       "41       mercatox       1  0.016775\n",
       "42  miningpoolhub       1  0.024854\n",
       "43           nexo       1  0.077567\n",
       "44           okex       1 -0.009932\n",
       "45            otc       1  0.222096\n",
       "46        paradex       1  0.018274\n",
       "47         parity       1  0.109977\n",
       "48          paxos       1  0.139004\n",
       "49       poloniex       1  0.039205\n",
       "50     quadrigacx       1  0.045673\n",
       "51     shapeshift       1  0.105848\n",
       "52          storj       1  0.095321\n",
       "53       switcheo       1  0.075756\n",
       "54         tether       1  0.160830\n",
       "55          upbit       1  0.008711"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_entity</th>\n      <th>target</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>airswap</td>\n      <td>1</td>\n      <td>0.046664</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>antpool</td>\n      <td>1</td>\n      <td>0.055153</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bancor</td>\n      <td>1</td>\n      <td>0.053066</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>binance</td>\n      <td>1</td>\n      <td>0.052430</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bitbox</td>\n      <td>1</td>\n      <td>0.079381</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bitclubpool</td>\n      <td>1</td>\n      <td>-0.004001</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bitfinex</td>\n      <td>1</td>\n      <td>0.006632</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>bithumb</td>\n      <td>1</td>\n      <td>-0.028046</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>bitmart</td>\n      <td>1</td>\n      <td>0.046159</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>bitstamp</td>\n      <td>1</td>\n      <td>0.034608</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>bittrex</td>\n      <td>1</td>\n      <td>0.011911</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>cobinhood</td>\n      <td>1</td>\n      <td>-0.038470</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>cobo</td>\n      <td>1</td>\n      <td>0.031416</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>coinbase</td>\n      <td>1</td>\n      <td>0.069406</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>coincheck</td>\n      <td>1</td>\n      <td>0.018296</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>coinex</td>\n      <td>1</td>\n      <td>0.010552</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>coinmine</td>\n      <td>1</td>\n      <td>0.038310</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>coinone</td>\n      <td>1</td>\n      <td>0.018185</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>coinrail</td>\n      <td>1</td>\n      <td>-0.018699</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>cryptokitties</td>\n      <td>1</td>\n      <td>0.059341</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>cryptopia</td>\n      <td>1</td>\n      <td>0.013216</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>dapp</td>\n      <td>1</td>\n      <td>0.097309</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>decentraland</td>\n      <td>1</td>\n      <td>-0.005803</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>deversifi</td>\n      <td>1</td>\n      <td>-0.024478</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>dex</td>\n      <td>1</td>\n      <td>0.087949</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>dragonex</td>\n      <td>1</td>\n      <td>-0.034751</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>etherdelta</td>\n      <td>1</td>\n      <td>-0.017438</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>ethfinex</td>\n      <td>1</td>\n      <td>0.036497</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>exmo</td>\n      <td>1</td>\n      <td>0.056855</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>fcoin</td>\n      <td>1</td>\n      <td>-0.015262</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>gemini</td>\n      <td>1</td>\n      <td>0.069898</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>hitbtc</td>\n      <td>1</td>\n      <td>0.027404</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>huobi</td>\n      <td>1</td>\n      <td>0.021553</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>hydro</td>\n      <td>1</td>\n      <td>0.028304</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>idex</td>\n      <td>1</td>\n      <td>0.043237</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>kraken</td>\n      <td>1</td>\n      <td>0.076676</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>kucoin</td>\n      <td>1</td>\n      <td>0.078712</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>latoken</td>\n      <td>1</td>\n      <td>0.019631</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>liquid</td>\n      <td>1</td>\n      <td>0.120405</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>luno</td>\n      <td>1</td>\n      <td>-0.025950</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>maker</td>\n      <td>1</td>\n      <td>0.072371</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>mercatox</td>\n      <td>1</td>\n      <td>0.016775</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>miningpoolhub</td>\n      <td>1</td>\n      <td>0.024854</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>nexo</td>\n      <td>1</td>\n      <td>0.077567</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>okex</td>\n      <td>1</td>\n      <td>-0.009932</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>otc</td>\n      <td>1</td>\n      <td>0.222096</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>paradex</td>\n      <td>1</td>\n      <td>0.018274</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>parity</td>\n      <td>1</td>\n      <td>0.109977</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>paxos</td>\n      <td>1</td>\n      <td>0.139004</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>poloniex</td>\n      <td>1</td>\n      <td>0.039205</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>quadrigacx</td>\n      <td>1</td>\n      <td>0.045673</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>shapeshift</td>\n      <td>1</td>\n      <td>0.105848</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>storj</td>\n      <td>1</td>\n      <td>0.095321</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>switcheo</td>\n      <td>1</td>\n      <td>0.075756</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>tether</td>\n      <td>1</td>\n      <td>0.160830</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>upbit</td>\n      <td>1</td>\n      <td>0.008711</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# retrieve rows that have entity names\n",
    "lr_df_entity = lr_df_averaged[lr_df_averaged.apply(lambda x: filter_entity(x[\"feature\"], entity_list), axis=1)]\n",
    "\n",
    "# label rows as their entity\n",
    "lr_df_entity[\"feature_entity\"] = lr_df_entity[\"feature\"].apply(lambda x: retrieve_entity(x, entity_list))\n",
    "\n",
    "# output entity \n",
    "lr_df_entity_grouped = lr_df_entity.groupby(\"feature_entity\").mean()\n",
    "lr_df_entity_grouped = lr_df_entity_grouped.reset_index()\n",
    "\n",
    "lr_df_entity_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "lr_df_averaged.to_csv(\"data/evaluation_lime/lime_word2vec_lr.csv\", index=False)\n",
    "lr_df_entity.to_csv(\"data/evaluation_lime/lime_entity_ungrouped_word2vec_lr.csv\", index=False)\n",
    "lr_df_entity_grouped.to_csv(\"data/evaluation_lime/lime_entity_word2vec_lr.csv\", index=False)"
   ]
  },
  {
   "source": [
    "## SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('featureembedder', FeatureEmbedder()),\n",
       "                ('svc', SVC(probability=True))])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# create pipeline\n",
    "vec = FeatureEmbedder()\n",
    "svm = SVC(probability=True)\n",
    "pipe_svm = make_pipeline(vec, svm)\n",
    "pipe_svm.fit(all_train.text, all_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve all features and weights from all possible texts\n",
    "for i in range(len(all_sample)):\n",
    "    current_text = all_sample[\"text\"].iloc[i]\n",
    "    \n",
    "    # create text explainer\n",
    "    te_svm = TextExplainer(random_state=42)\n",
    "    te_svm.fit(current_text, pipe_svm.predict_proba)\n",
    "\n",
    "    # create dataframe from weights\n",
    "    current_df = eli5.formatters.as_dataframe.format_as_dataframes(te_svm.explain_weights(top=None))[\"targets\"]\n",
    "\n",
    "    if i == 0:\n",
    "        svm_df = current_df\n",
    "    else:\n",
    "        svm_df = pd.concat([current_df, svm_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve mean of each weight\n",
    "svm_df_averaged = svm_df.groupby(\"feature\").mean()\n",
    "svm_df_averaged = svm_df_averaged.reset_index()\n",
    "\n",
    "svm_df_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve rows that have entity names\n",
    "svm_df_entity = svm_df_averaged[svm_df_averaged.apply(lambda x: filter_entity(x[\"feature\"], entity_list), axis=1)]\n",
    "\n",
    "# label rows as their entity\n",
    "svm_df_entity[\"feature_entity\"] = svm_df_entity[\"feature\"].apply(lambda x: retrieve_entity(x, entity_list))\n",
    "\n",
    "# output entity \n",
    "svm_df_entity_grouped = svm_df_entity.groupby(\"feature_entity\").mean()\n",
    "svm_df_entity_grouped = svm_df_entity_grouped.reset_index()\n",
    "\n",
    "svm_df_entity_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "svm_df_averaged.to_csv(\"data/evaluation_lime/lime_word2vec_svm.csv\", index=False)\n",
    "svm_df_entity.to_csv(\"data/evaluation_lime/lime_entity_ungrouped_word2vec_svm.csv\", index=False)\n",
    "svm_df_entity_grouped.to_csv(\"data/evaluation_lime/lime_entity_word2vec_svm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual text explainer\n",
    "# te_svm = TextExplainer(random_state=42)\n",
    "# te_svm.fit(all_test.text.iloc[1], pipe_svm.predict_proba)\n",
    "# te_svm.explain_weights(top=None)"
   ]
  },
  {
   "source": [
    "## Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "vec = FeatureEmbedder()\n",
    "rf = RandomForestClassifier()\n",
    "pipe_rf = make_pipeline(vec, rf)\n",
    "pipe_rf.fit(all_train.text, all_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve all features and weights from all possible texts\n",
    "for i in range(len(all_sample)):\n",
    "    current_text = all_sample[\"text\"].iloc[i]\n",
    "    \n",
    "    # create text explainer\n",
    "    te_rf = TextExplainer(random_state=42)\n",
    "    te_rf.fit(current_text, pipe_svm.predict_proba)\n",
    "\n",
    "    # create dataframe from weights\n",
    "    current_df = eli5.formatters.as_dataframe.format_as_dataframes(te_rf.explain_weights(top=None))[\"targets\"]\n",
    "\n",
    "    if i == 0:\n",
    "        rf_df = current_df\n",
    "    else:\n",
    "        rf_df = pd.concat([current_df, rf_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve mean of each weight\n",
    "rf_df_averaged = rf_df.groupby(\"feature\").mean()\n",
    "rf_df_averaged = rf_df_averaged.reset_index()\n",
    "\n",
    "rf_df_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve rows that have entity names\n",
    "rf_df_entity = rf_df_averaged[rf_df_averaged.apply(lambda x: filter_entity(x[\"feature\"], entity_list), axis=1)]\n",
    "\n",
    "# label rows as their entity\n",
    "rf_df_entity[\"feature_entity\"] = rf_df_entity[\"feature\"].apply(lambda x: retrieve_entity(x, entity_list))\n",
    "\n",
    "# output entity \n",
    "rf_df_entity_grouped = rf_df_entity.groupby(\"feature_entity\").mean()\n",
    "rf_df_entity_grouped = rf_df_entity_grouped.reset_index()\n",
    "\n",
    "rf_df_entity_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "rf_df_averaged.to_csv(\"data/evaluation_lime/lime_word2vec_rf.csv\", index=False)\n",
    "rf_df_entity.to_csv(\"data/evaluation_lime/lime_entity_ungrouped_word2vec_rf.csv\", index=False)\n",
    "rf_df_entity_grouped.to_csv(\"data/evaluation_lime/lime_entity_word2vec_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}