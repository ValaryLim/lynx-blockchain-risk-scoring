{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# optional text processing\n",
    "from utils.text_processing import text_processing\n",
    "\n",
    "# model training\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Train-Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "path = \"data/train_test/\"\n",
    "csvs = [\"all_train.csv\", \"all_test.csv\", \"news_test_entity.csv\", \"reddit_test_entity.csv\", \"twitter_test.csv\"]\n",
    "data = {}\n",
    "\n",
    "for csv in csvs:\n",
    "    df = pd.read_csv(path+csv, header=0)\n",
    "    # extract relevant columns\n",
    "    df = pd.DataFrame(df[['text', 'label']])\n",
    "    \n",
    "    # processing text column (where necessary)\n",
    "    df['text'] = df.apply(lambda x: text_processing(x.text,                     \n",
    "                                                    lower=False, \n",
    "                                                    remove_url=True, \n",
    "                                                    remove_punctuation=False, \n",
    "                                                    remove_stopwords=False, \n",
    "                                                    replace_entity=True, \n",
    "                                                    replace_hash=True,\n",
    "                                                    split_alphanumeric=False,\n",
    "                                                    lemmatize=False,\n",
    "                                                    stem=False), axis=1)\n",
    "    \n",
    "    # rename columns - requirement of the simpletransformers package\n",
    "    df = df.rename({'label': 'labels'}, axis=1)\n",
    "    # check shape of df\n",
    "    print(\"\\nShape: \", df.shape)\n",
    "    # check null\n",
    "    print(\"Check null: \", df.isnull().sum().sum())\n",
    "    # check head\n",
    "    display(df.head(3))\n",
    "    # add to data dict\n",
    "    data[csv] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading 2020 Data for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "path = \"data/2020/\"\n",
    "\n",
    "csvs = [\"2020_conventional.csv\", \"2020_crypto.csv\", \"2020_reddit.csv\", \"2020_twitter.csv\"]\n",
    "\n",
    "data = {}\n",
    "\n",
    "for csv in csvs:\n",
    "    df = pd.read_csv(path+csv, header=0)\n",
    "    # extract relevant columns\n",
    "    if csv == \"2020_reddit.csv\":\n",
    "        df = pd.DataFrame(df[['title', 'excerpt']])\n",
    "        df['text'] = df['title']\n",
    "    elif csv == \"2020_twitter.csv\":\n",
    "        df = pd.DataFrame(df[['tweet']])\n",
    "        df.columns = ['text']\n",
    "    else:\n",
    "        df = pd.DataFrame(df[['title', 'excerpt']])\n",
    "        df['text'] = df['title'] + '' + df['excerpt']\n",
    "    \n",
    "    # check shape of df\n",
    "    print(\"\\nShape: \", df.shape)\n",
    "    # check null\n",
    "    print(\"Check null: \", df.isnull().sum().sum())\n",
    "    # check head\n",
    "    display(df.head(3))\n",
    "    # add to data dict\n",
    "    data[csv] = df[['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Transformers Model\n",
    "- Documentation: https://simpletransformers.ai/docs/binary-classification/ \n",
    "- Model Types: https://simpletransformers.ai/docs/classification-specifics/#supported-model-types\n",
    "- Github: https://github.com/ThilinaRajapakse/simpletransformers\n",
    "- Tutorials: \n",
    "    - https://towardsdatascience.com/simple-transformers-introducing-the-easiest-bert-roberta-xlnet-and-xlm-library-58bf8c59b2a3\n",
    "    - https://medium.com/towards-artificial-intelligence/text-classification-with-simple-transformers-a29d13358135\n",
    "    - https://towardsdatascience.com/battle-of-the-transformers-electra-bert-roberta-or-xlnet-40607e97aba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise Model\n",
    "model_args = ClassificationArgs(num_train_epochs=2, learning_rate = 5e-5, \\\n",
    "                                output_dir='models/bert/outputs')\n",
    "model = ClassificationModel(model_type = 'roberta', model_name = 'roberta-base', \\\n",
    "                            args = model_args, use_cuda = False)\n",
    "\n",
    "# other model_type & model_name combinations\n",
    "# bert & bert-base-cased\n",
    "# bert & bert-base-uncased\n",
    "# bert & textattack/bert-base-uncased-yelp-polarity\n",
    "# electra & google/electra-base-discriminator\n",
    "# roberta & roberta-base\n",
    "# bert & bert-base-uncased\n",
    "# distilbert & distilbert-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.train_model(data['all_train.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading saved models\n",
    "# under model names: input path to a directory containing model files\n",
    "# must specify the same args as model initialisation\n",
    "model_args = ClassificationArgs(num_train_epochs=2, learning_rate = 5e-5)\n",
    "model = ClassificationModel(model_type = 'roberta', model_name = 'models/bert/outputs_roberta_hash_entity_url/', \\\n",
    "                            args = model_args, use_cuda = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to store results\n",
    "results = pd.DataFrame(columns = ['test_set', 'precision', 'recall', 'f1'])\n",
    "\n",
    "# evaluation on test sets\n",
    "for csv in csvs[1:]:\n",
    "    test_df = data[csv]\n",
    "    # evaluate the model\n",
    "    # result, model_outputs, wrong_predictions = model.eval_model(test_df)\n",
    "    \n",
    "    # get predictions\n",
    "    pred, raw_outputs = model.predict(test_df['text'])\n",
    "    \n",
    "    # append prediction (0 or 1) and probability (prob) to original dataframe\n",
    "    df = pd.read_csv(path+csv)\n",
    "    df['pred'] = pred\n",
    "    for i in range(len(df)):\n",
    "        df.loc[i, 'raw_output_0'] = raw_outputs[i][0]\n",
    "        df.loc[i, 'raw_output_1'] = raw_outputs[i][1]\n",
    "        \n",
    "    probabilities = softmax(raw_outputs, axis=1)\n",
    "    probabilities_1 = [x[1] for x in probabilities]\n",
    "    df['prob'] = probabilities_1\n",
    "    \n",
    "    # export\n",
    "    df.to_csv(\"data/predicted_bert/roberta_base_\"+csv, index=False)\n",
    "    \n",
    "    # flip it for Yelp (0 negative and 1 positive)\n",
    "    # pred_flipped = (pred - 1) * (-1)\n",
    "    \n",
    "    # classification report\n",
    "    report = classification_report(y_true = test_df['labels'], y_pred = pred, output_dict = True)\n",
    "    \n",
    "    row = {'test_set': csv, 'precision': report['1']['precision'], \\\n",
    "           'recall': report['1']['recall'], 'f1': report['1']['f1-score']}\n",
    "    \n",
    "    print(row)\n",
    "    \n",
    "    results = results.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020 Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on 2020 data\n",
    "for csv in csvs:\n",
    "    test_df = data[csv]\n",
    "    # evaluate the model\n",
    "    # result, model_outputs, wrong_predictions = model.eval_model(test_df)\n",
    "    \n",
    "    # get predictions\n",
    "    pred, raw_outputs = model.predict(test_df['text'])\n",
    "    \n",
    "    # append prediction (0 or 1) and probability (prob) to original dataframe\n",
    "    df = pd.read_csv(path+csv)\n",
    "    df['pred'] = pred\n",
    "    for i in range(len(df)):\n",
    "        df.loc[i, 'raw_output_0'] = raw_outputs[i][0]\n",
    "        df.loc[i, 'raw_output_1'] = raw_outputs[i][1]\n",
    "        \n",
    "    probabilities = softmax(raw_outputs, axis=1)\n",
    "    probabilities_1 = [x[1] for x in probabilities]\n",
    "    df['text'] = test_df['text']\n",
    "    df['prob'] = probabilities_1\n",
    "    \n",
    "    # export\n",
    "    df.to_csv(path+\"bert/2020_bert_\"+csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
